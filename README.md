## Project Structure and File Descriptions


### Main files

1. `model.py`

Contains the definition of the PPO (Proximal Policy Optimization) model architecture and configuration.

2. `train.py`

Training script for individual models. Includes configuration settings and training loops for RL agents.

3. `test.py`

Testing script for individual models. Set `render=True` in the config dictionary for visualization (port forwarding may be required when connecting to remote servers).

4. `human_demonstrations.py`

Allows human gameplay to generate demonstrations. LLM summarizes rules from these demonstrations.

5. `planning.py`

LLM-based task planning module. Generates two files containing planning lists: one in natural language and one using environment object representations for subsequent subtask extraction.

6. `propose_subRLs.py`

Generates a descriptive JSON dictionary for sub-RL models and a reward wrapper file based on the planning output and summarized rules for model training.

7. `train_sub_models.py`

Training script for sub-RL models using the configurations generated by the previous step.

8. `llm_agent_ironpickaxe.py`

Integrates all trained sub-models. LLM orchestrates model calls based on rules, demonstrating superior performance compared to baseline approaches.

9. `temp_result`

Directory containing all intermediate results generated by LLM during the planning and analysis process.

10. `utils`

Utility module containing helper functions and environment wrappers:

 `InitWrapper`: Initializes inventory slots in the environment. Example:

```python
env = InitWrapper(env, ["stone_pickaxe", "wood"], [1, 2])
```
This adds one stone pickaxe and two wood pieces to the starting inventory. Can be configured in the config dictionaries of `train.py` and `test.py`.

11. `example_info.txt`

Example output showing the memory information returned after an environment step.

12. `crafter`

Contains the implementation of the Crafter environment.

13. `RL_models2`

Directory containing pre-trained sub-reinforcement learning models.



### Notes

1. Modified Crafter Environment:  
   This project uses a modified version of the Crafter environment that may not be compatible with the standard version installed via `pip`. It is recommended to create a new virtual environment and install dependencies using:
```bash
pip install -r requirements.txt
```
2. DeepSeek API Configuration:
The project utilizes the DeepSeek 67B model. Before running the code, set the environment variable DEEPSEEK_API_KEY with your API key.
To confirm the environment variable is properly set, run:

```bash
echo $DEEPSEEK_API_KEY
```


### Running with Prolog Integration

This project implements `get_stone_pickaxe` in `prolog_run.pl`, demonstrating hierarchical task execution through Prolog-Python integration. Ensure **Scryer Prolog** is installed in your environment before proceeding (download from: https://github.com/mthom/scryer-prolog).

#### Usage Instructions

1. **Start the Python Socket Server**  
   Open a terminal and run:
```bash
python scpl_server.py
```
2. **Launch Prolog Client**
  Open another terminal and start Scryer Prolog with the run script:
```bash
scryer-prolog prolog_run.pl
```
3. **Execute the Query**
   In the Prolog interpreter, run:
```bash
?- run("MyCrafter-v0").
```
#### Expected Output
Success:If the agent completes the stone pickaxe acquisition task, the query will return containing `true`.

Failure:If the task is not completed, the query will return `false`.

